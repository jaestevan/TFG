{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd \n",
    "\n",
    "data_root_folder = os.path.join(os.getcwd(), \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84323c2",
   "metadata": {},
   "source": [
    "Responses from Phi sometimes gives error. The processing notebook have been created to save the current results in a file and restart ignoring the previously configured questions. The next questions will be saved to a new file until a new error occurs or all the questions are processed.\n",
    "\n",
    "This piece of code here merges incremental result files from interrupted runs into a single file for the same catgory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc25c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.path.join(data_root_folder, \"temp\", \"*.csv\")\n",
    "output_df = pd.DataFrame()\n",
    "for f in glob.glob(filenames):\n",
    "    s = f.split(\"--\")\n",
    "    cat = s[0].split(\"\\\\\")[-1]\n",
    "    model = s[1]\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "    output_file = os.path.join(data_root_folder, \"merged\", f\"{cat}--{model}.csv\")\n",
    "    output_df.to_csv(\n",
    "        output_file, \n",
    "        index=False, \n",
    "        quoting=csv.QUOTE_NONNUMERIC, \n",
    "        encoding='utf-8')\n",
    "\n",
    "    print(f\"Merged {len(glob.glob(filenames))} files into {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05200015",
   "metadata": {},
   "source": [
    "This code combines the results file obtained from my experiment with the original BBQ file, to have all the metadata available in the same file for data analysis.\n",
    "\n",
    "This also extract 'additional_metadata' from BBQ to single columns in the a CSV, including One Hot encoding for  'stereotyped_groups'\n",
    "\n",
    "Interesting refs from pandas:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbq_dataset import BBQ_CATEGORIES, fetch_bbq_dataframe\n",
    "\n",
    "filenames = os.path.join(data_root_folder, \"merged\", \"*.csv\")\n",
    "for f in glob.glob(filenames):\n",
    "    s = f.split(\"--\")\n",
    "    cat = s[0].split(\"\\\\\")[-1]\n",
    "    model = s[1].removesuffix(\".csv\")\n",
    "    bbq_filename = os.path.join(data_root_folder, \"bbq\", BBQ_CATEGORIES.get(cat))\n",
    "\n",
    "    # Reads the original BBQ json file\n",
    "    try:\n",
    "        json_df = pd.read_json(bbq_filename, lines=True)\n",
    "        json_df.set_index(\"example_id\", inplace=True, drop=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {bbq_filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # extract additional metadata to single columns in the dataframe\n",
    "    meta = json_df[\"additional_metadata\"].apply(lambda x: {} if pd.isna(x) else x).apply(pd.Series)[[\"subcategory\", \"stereotyped_groups\", \"version\", \"source\"]]\n",
    "    json_df.drop(columns=[\"additional_metadata\"], inplace=True)\n",
    "\n",
    "    # extracts a new field to flag if the label is the unknown answer\n",
    "    bbq_df = fetch_bbq_dataframe(category=cat, root_folder=os.path.join(data_root_folder, \"bbq\"))\n",
    "    bbq_df = bbq_df.filter([\"example_id\", \"correct_answer_unknown\"]).rename(columns={\"correct_answer_unknown\": \"label_is_unknown\"})\n",
    "    json_df.reset_index(drop = True, inplace = True)\n",
    "    bbq_df.reset_index(drop = True, inplace = True)\n",
    "    json_df = pd.merge(json_df, bbq_df, on=\"example_id\")\n",
    "\n",
    "    # one-hot encoding as extra columns in the dataframe\n",
    "    meta = meta['stereotyped_groups'].str.join('|').str.lower().str.get_dummies(sep='|')\n",
    "        \n",
    "    # Reads my results CSV file\n",
    "    try:\n",
    "        csv_df = pd.read_csv(f)\n",
    "        csv_df.set_index(\"example_id\", inplace=True, verify_integrity=True)\n",
    "        csv_df.drop(columns=[\"question\"], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Merge the dataframes into a single one\n",
    "    res_df = pd.concat([json_df, csv_df, meta], axis=1).reindex(json_df.index)\n",
    "    #print(res_df.info())\n",
    "\n",
    "    # Extracts the dataframe into a CSV file\n",
    "    output_file = os.path.join(data_root_folder, \"final\", f\"{cat}--{model}.csv\")\n",
    "    res_df.to_csv(\n",
    "        output_file, \n",
    "        index=False, \n",
    "        quoting=csv.QUOTE_NONNUMERIC, \n",
    "        encoding='utf-8')\n",
    "\n",
    "    print(f\"Merged {f} into {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1c9aa",
   "metadata": {},
   "source": [
    "This piece of code merges all the results from the same bbq category obtained from different modules into a same CSV for data analysis. \n",
    "\n",
    "These are the files used on the data analysis section of the final memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e267246",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbq_category = \"disability_status\"\n",
    "\n",
    "filenames = os.path.join(data_root_folder, \"final\", bbq_category + \"--*.csv\")\n",
    "output_df = pd.DataFrame()\n",
    "for f in glob.glob(filenames):\n",
    "    s = f.split(\"--\")\n",
    "    cat = s[0].split(\"\\\\\")[-1]\n",
    "    model = s[1].removesuffix(\".csv\")\n",
    "\n",
    "    if model == 'ALL':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "        df.insert(loc=0, column='Model', value=model)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "    output_file = os.path.join(data_root_folder, \"final\", f\"{cat}--ALL.csv\")\n",
    "    output_df.to_csv(\n",
    "        output_file, \n",
    "        index=False, \n",
    "        quoting=csv.QUOTE_NONNUMERIC, \n",
    "        encoding='utf-8')\n",
    "    print(f\"Merged {f} into {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
